from dataclasses import dataclass
from typing import List, Tuple
import logging

import ml_dtypes # support for bfloat16 dtype
import numpy as np

import os
from pathlib import Path
import re
import subprocess
import shutil
import pytest
import json

from iree.compiler.ir import Context, Module

from .aws_fpga import FpgaSession, RemoteFpgaSession
from .remote_testing import RemoteTestRunner
from .versioned_fixtures import VersionedFile, versioned_unhashable_object_fixture, versioned_static_file_fixture, versioned_generated_file_fixture, \
                                versioned_cached_data_fixture, versioned_hashable_object_fixture, versioned_generated_directory_fixture
from torq.performance import annotate_host_profile_from_files
from torq.model_profiler.generate_perfetto_combined_report import generate_html, extract_model_name, extract_perfetto_summary

logger = logging.getLogger("torq.testing.iree")

TOPDIR = Path(__file__).parent.parent.parent.parent


MODELS_DIR = TOPDIR / 'tests/testdata/'
BUILD_DIR = Path(os.environ.get('IREE_BUILD_DIR', str(TOPDIR.parent / 'iree-build')))
SOC_BUILD_DIR = Path(os.environ.get('IREE_SOC_BUILD_DIR', str(TOPDIR.parent / 'iree-build-soc')))


def pytest_addoption(parser):
    parser.addoption("--debug-ir", nargs='?', const=True, default=False, help="Enable detailed IR dump of after each pass (optionally set the dump directory)")
    parser.addoption("--generate-hw-test-vectors", action="store_true", default=False, help="Generate hardware test vectors")
    parser.addoption("--hw-test-vector-output-dir", default=False, help="Store hardware test vectors generated by test_torqrt.py in this directory")
    parser.addoption("--extra-torq-compiler-options", default=[], help="Add these extra options when compiling with the torq backend (use quotes to pass multiple arguments)")
    parser.addoption("--extra-torq-runtime-options", default=[], help="Add these extra options when executing a module with the torq runtime (use quotes to pass multiple arguments)")
    parser.addoption("--llvmcpu-compiler-options", default=[], help="Add these extra options when compiling with the torq backend (use quotes to pass multiple arguments)")
    parser.addoption("--llvmcpu-runtime-options", default=[], help="Add these extra options when executing a module with the torq runtime (use quotes to pass multiple arguments)")

    parser.addoption("--no-phases-dump", action="store_true", default=False, help="Disable phase dumps in torq compiler")
    parser.addoption("--debug-torq-compiler", type=int, default=0, help="Run torq compiler under gdb")
    parser.addoption("--trace-buffers", action="store_true", default=False, help="Enable tracing of buffers in the torq runtime")
    parser.addoption("--torq-runtime-hw-type", action="store", default="sim", help="Command separate list of target hw to use for torq tests (sim, aws_fpga)")
    parser.addoption("--torq-chips", action="store", default="default", help="Command separate list of chips to compile models for")
    parser.addoption("--ignore-binary-mtime", action="store_true", default=False, help="Ignore binary mtime of binaries when deciding to invalidate cached fixtures")
    parser.addoption("--torq-compiler-timeout", type=int, default=60*5, help="Timeout in seconds for torq compiler invocations")
    parser.addoption("--torq-runtime-timeout", type=int, default=60*4, help="Timeout in seconds for torq runtime invocations")
    parser.addoption("--torq-compile-time-profiling-output-dir", default=None, help="Directory to save per-test compile time profiling outputs")
    parser.addoption("--torq-runtime-profiling-output-dir", default=None, help="Directory to save per-test profiling outputs")
    parser.addoption("--torq-addr", default=None, help="SSH address to run tests remotely")
    parser.addoption("--torq-port", default=22, help="SSH port to run tests remotely")
    
def pytest_generate_tests(metafunc):
    if 'runtime_hw_type' in metafunc.fixturenames:

        runtime_hw_type = metafunc.config.getoption("torq_runtime_hw_type").split(",")

        metafunc.parametrize('runtime_hw_type', runtime_hw_type, indirect=True)

        if metafunc.config.getoption("torq_chips") == 'all':
            chips = get_latest_chips()
        elif metafunc.config.getoption("torq_chips").endswith('.group'):
            with open(Path(TOPDIR / 'extras' / 'chips' / metafunc.config.getoption("torq_chips")), 'r') as f:
                chips = f.read().splitlines()
        else:
            chips = metafunc.config.getoption("torq_chips").split(",")

        if len(chips) == 0:
            raise ValueError("No chips found for torq tests")

        metafunc.parametrize('chip_config', chips, indirect=True)


def get_latest_chips():
    configs_dir = TOPDIR / 'extras' / 'chips'

    return [ f.resolve().stem for f in configs_dir.iterdir() if f.stem.endswith('latest') ]


@versioned_hashable_object_fixture
def chip_config(request):

    if request.param == 'default':

        return {
            "target": "SL2610"
        }    


    config_file = TOPDIR / 'extras' / 'chips' / f'{request.param}.json'

    if not config_file.exists():
        return {
            "target": request.param
        }

    with open(TOPDIR / 'extras' / 'chips' / f'{request.param}.json', 'r') as f:
        return json.load(f)


def _find_iree_tool(env_var, tool_name):
    """Find IREE tool binary, checking environment variable first, then BUILD_DIR fallback."""

    # Check environment variable first
    env_path = os.getenv(env_var)
    if env_path:
        return env_path
    
    # Fall back to BUILD_DIR based path
    fallback_paths = [BUILD_DIR / 'third_party/iree/tools' / tool_name,
                      BUILD_DIR / 'runtime/tools' / tool_name,
                      BUILD_DIR / 'compiler/tools' / tool_name]
    for path in fallback_paths:
        if path.exists():
            return str(path)

    # Check if tool is in the path
    tool_path = shutil.which(tool_name)
    if tool_path:
        return tool_path

    raise FileNotFoundError(f"Could not find {tool_name}.")


@versioned_hashable_object_fixture
def iree_opt():
    return _find_iree_tool('IREE_OPT', 'iree-opt')



def get_input_type_options(input_path):
    """
    Auto-detects the pipeline suitable to run the MLIR input file
    """

    with open(input_path, 'r') as mlir_file:
        mlir_content = mlir_file.read()
    if "torch.onnx" in mlir_content:
        return ['--iree-input-type=onnx-torq']
    elif "torch." in mlir_content:
        return ['--iree-input-type=torch-torq']
    return []


def create_output_args(output_path_root, output_specs):
    """
    Creates the output command line args to invoke torq-run-module
    """    

    output_args = []

    for output_path in create_output_paths(output_path_root, output_specs):
        output_args.append(f'--output=@{output_path}')

    return output_args


def create_output_paths(output_path_root, output_specs):
    """
    Creates the paths for the outputs of torq-run-module
    """    
    
    output_paths = []

    for idx, tensor_type in enumerate(output_specs):
        output_path = f'{output_path_root}/output_{idx}.bin'
        output_paths.append(output_path)

    return output_paths


def load_outputs(output_specs, output_paths):
    """
    Reads the data saved as outputs from torq-run-module
    """
    output_data = []

    for idx, tensor_type in enumerate(output_specs): 
        with open(output_paths[idx], 'rb') as f:
            data = np.frombuffer(f.read(), dtype=get_dtype(tensor_type.fmt)
                                 ).reshape(tensor_type.shape)
            output_data.append(data)
            
    return output_data


def get_dtype(name):
    """
    Returns the numpy dtype corresponding to the given MLIR type name
    """

    dict_types = {'i1': bool,
                  'i8': np.int8,
                  'i16': np.int16,
                  'i32': np.int32,              
                  'ui8': np.uint8,
                  'f16': np.float16,
                  'f32': np.float32,
                  'si8': np.int8,
                  'si16': np.int16,
                  'si64': np.int64,
                  'si32': np.int32,
                  'bf16': ml_dtypes.bfloat16
                  }
    
    if name in dict_types:
        return dict_types[name]
        
    raise ValueError(f"Unsupported dtype {name}")


def is_float_type(dtype):
    """
    Returns true if the given dtype is a floating point type (either numpy native or bfloat16)
    """
    return np.issubdtype(dtype, np.floating) or dtype == ml_dtypes.bfloat16


@dataclass
class TensorType:    
    """
    Represents the type of a tensor input or output of an MLIR model
    """

    shape: List[int]
    fmt: str
    
    def to_arg(self):
        return "x".join([str(x) for x in self.shape] + [self.fmt])

    @staticmethod
    def from_string(spec):
        *shape_str, fmt = spec.split('x')
        shape = [int(s) for s in shape_str]
        return TensorType(shape, fmt)


@dataclass
class MlirIoSpec:
    inputs: List[TensorType]
    outputs: List[TensorType]


@versioned_cached_data_fixture
def mlir_io_spec(request, mlir_model_file):

    with open(mlir_model_file, 'r') as mlir_file:
        mlir_content = mlir_file.read()

    module = Module.parse(mlir_content, Context())
    for op in module.body.operations:
        input_types = []
        output_types = []

        for region in op.regions:
            for block in region.blocks:
                for arg in block.arguments:
                    input_types.append(str(arg.type))

                for inner_op in block.operations:
                    if inner_op.name == "func.return":
                        for i, operand in enumerate(inner_op.operands):
                            output_types.append(str(operand.type))

    input_specs = []
    output_specs = []

    def get_torch_specs(input):
        match = re.match(r"!torch\.vtensor<\[(.*)\],(\w+)>", input)

        if match and match.group(1) == '':
            shape = []
        else:
            shape = [int(x) for x in match.group(1).split(',')] if match else None

        if match:
            dtype = match.group(2)
            return TensorType(shape, dtype)
        else:
            return None

    def get_tosa_specs(input):
        match = re.match(r"tensor<([^>]+)>", input)
        if match:
            return TensorType.from_string(match.group(1))
        else:
            return None

    for t in input_types:
        input_specs.append(get_torch_specs(t))
    for t in output_types:
        output_specs.append(get_torch_specs(t))

    if None in input_specs or None in output_specs:
        input_specs = []
        output_specs = []

        for t in input_types:
            input_specs.append(get_tosa_specs(t))
        for t in output_types:
            output_specs.append(get_tosa_specs(t))

    return MlirIoSpec(inputs=input_specs, outputs=output_specs)


@pytest.fixture
def torq_compiler(request):
    """
    This fixture returns the path to the torq compiler binary.

    It is automatically invalidated when the compiler binary or the library changes.
    """

    file_path = _find_iree_tool('TORQ_COMPILE', 'torq-compile')
            
    if request.config.getoption("--ignore-binary-mtime"):
        compiler_mtime = 0
    else:
        compiler_mtime = os.path.getmtime(file_path)

    version = "torq_compiler_" + str(compiler_mtime)

    print("[compiler] " + "torq_compiler" + f" -> {file_path}")

    return VersionedFile(file_path, version)


# this fixture is assumed to always have the same version so we don't need
# to rebuild dependent fixtures when the compiler mtime or its path changes
@versioned_unhashable_object_fixture
def llvmcpu_compiler():
    """
    This fixture returns the path to the compiler binary.

    It is not invalidated when the compiler binary mtime changes.
    """

    return _find_iree_tool('IREE_COMPILE', 'iree-compile')


@pytest.fixture
def torq_runtime(request):
    """
    This fixture returns the path to the torq runtime binary.

    It is automatically invalidated when the runtime binary mtime changes.
    """

    file_path = _find_iree_tool('TORQ_RUN_MODULE', 'torq-run-module')

    if request.config.getoption("--ignore-binary-mtime"):
        runtime_mtime = 0
    else:
        runtime_mtime = os.path.getmtime(file_path)

    version = "torq_runtime_" + str(runtime_mtime)

    return VersionedFile(file_path, version)


# this fixture is assumed to always have the same version so we don't need
# to rebuild dependent fixtures when the compiler mtime or its path changes
@versioned_unhashable_object_fixture
def llvmcpu_runtime():
    """
    This fixture returns the path to the runtime binary.

    It is not invalidated when the runtime binary mtime changes.
    """

    return _find_iree_tool('IREE_RUN_MODULE', 'iree-run-module')


@versioned_unhashable_object_fixture
def iree_input_data_args(iree_input_data, mlir_io_spec):
    input_args = []
    
    for i, tensor_type in enumerate(mlir_io_spec.inputs):        
        file_name = iree_input_data / f'in_rnd_{i}.bin'        
        input_args.append(f'--input={tensor_type.to_arg()}=@{file_name}')        

    return input_args


@versioned_generated_directory_fixture
def iree_input_data(request, versioned_dir, input_data):
    """
    Save the received test data for inference
    """

    for i, data in enumerate(input_data):
        file_name = versioned_dir / f'in_rnd_{i}.bin'

        with open(file_name, 'wb') as f:
            f.write(data.tobytes())

        np.save(str(file_name) + '.npy', data)


@pytest.fixture
def mlir_static_file(case_config):
    return case_config['mlir_file_name']


@pytest.fixture
def mlir_model_file(request, case_config):
    return request.getfixturevalue(case_config['mlir_model_file'])


@versioned_hashable_object_fixture
def runtime_hw_type(request):
    return request.param


@versioned_hashable_object_fixture
def torq_compiler_options(request, case_config):

    cmds = case_config.get("torq_compiler_options", [])

    if request.config.getoption("--extra-torq-compiler-options"):
        cmds.extend(request.config.getoption("--extra-torq-compiler-options").split(" "))
    
    if request.config.getoption("--trace-buffers"):
        cmds.append('--torq-enable-buffer-debug-info')

    gdb_port = request.config.getoption('--debug-torq-compiler')
    if gdb_port > 0:
        cmds = ['gdbserver', 'localhost:' + str(gdb_port)] + cmds

    return cmds


@versioned_hashable_object_fixture
def torq_compiler_timeout(request, case_config):
    return int(case_config.get("torq_compiler_timeout", request.config.getoption("--torq-compiler-timeout")))


@versioned_hashable_object_fixture
def enable_debug_ir(request):
    return request.config.getoption("--debug-ir")


@versioned_hashable_object_fixture
def enable_phases_dump(request):
    return not request.config.getoption("--no-phases-dump", False)


@versioned_generated_directory_fixture
def torq_compiled_model_dir(versioned_dir, torq_compiler_options, request, mlir_model_file, torq_compiler, chip_config, 
                            torq_compiler_timeout, enable_debug_ir, enable_hw_test_vectors, enable_phases_dump, runtime_hw_type):
    
    model_file = versioned_dir / 'model.vmfb'

    target = chip_config.get("target", "SL2610")

    cmds = [str(torq_compiler), str(mlir_model_file), '-o', str(model_file)]

    # FIXME: bf16 softmax op has accuracy issue on Slice, force Host execution for now.
    cmds += ["--torq-execute-on-host=softmax"]

    if target == "custom":
        cmds.append(f'--torq-hw={chip_config["lram_size"]}:{chip_config["slice_count"]}:{chip_config["tiling_memory"]}:'
                     f'{chip_config.get("css_features","")}:{chip_config.get("nss_features","")}')
    else:
        cmds.append(f'--torq-hw={target}')

    if enable_debug_ir is not False:
        if enable_debug_ir is True:            
            dump_path = versioned_dir / 'ir'
        else:
            dump_path = Path(request.config.rootdir) / enable_debug_ir

        cmds.extend(['--mlir-print-ir-after-all', f'--mlir-print-ir-tree-dir={dump_path}'])

    if enable_phases_dump:
        cmds.append(f'--dump-compilation-phases-to={versioned_dir}/phases')

    if enable_hw_test_vectors:
        cmds.append(f'--torq-dump-descriptors-dir={versioned_dir}/cfgdesc')

    # when the runtime is cmodel, we need to compile with qemu address map
    if runtime_hw_type == 'sim':
        cmds.append('--torq-css-qemu')
    elif runtime_hw_type == 'astra_machina':
        # For SoC/hardware targets, use cross-compilation settings
        # Don't add --torq-css-qemu for actual hardware
        cmds.extend([
                "--torq-target-host-triple=aarch64-unknown-linux-gnu",
                "--torq-target-host-cpu=generic",
                "--torq-target-host-cpu-features=+neon,+crypto,+crc,+dotprod,+rdm,+rcpc,+lse"
            ])
    cmds += get_input_type_options(mlir_model_file)

    cmds += torq_compiler_options
    
    # Enable compiler profiling by default. If output dir is not specified, use the vmfb folder.
    compile_time_profiling_output_dir = request.config.getoption("--torq-compile-time-profiling-output-dir")
    
    if compile_time_profiling_output_dir is None:
        compile_time_profiling_output_dir = versioned_dir

    compiler_profile_csv = versioned_dir / 'compiler_profile.csv'
    cmds.extend(['--torq-enable-profiling', f'--torq-dump-profiling={compiler_profile_csv}'])
    
    print("Compiling for TORQ with: " + " ".join(cmds))

    with request.getfixturevalue("scenario_log").event("torq_compile"):
        subprocess.check_call(cmds, cwd=str(versioned_dir), timeout=torq_compiler_timeout)

    # Save compile time profiling data if requested
    if compile_time_profiling_output_dir is not None and compiler_profile_csv is not None:
        compile_time_profiling_output_dir = Path(compile_time_profiling_output_dir)
        compile_time_profiling_output_dir.mkdir(parents=True, exist_ok=True)
        
        # Copy the compiler-generated profile to the output directory with test name
        output_compile_profile = compile_time_profiling_output_dir / f'{request.node.name}_compile.csv'
        if compiler_profile_csv.exists():
            shutil.copy(compiler_profile_csv, output_compile_profile)
            print(f"✓ Saved compile time profile: {output_compile_profile}")
            
            # Generate Perfetto .pb file from compile time profile
            try:
                from torq.model_profiler.perfetto_logger import convert_to_perfetto, calculate_compile_profile_metrics
                
                # Calculate metrics for the compile profile
                overview_data = calculate_compile_profile_metrics(str(output_compile_profile))
                overview_map = {request.node.name: overview_data}
                
                # Generate .pb file
                pb_output_path = compile_time_profiling_output_dir / f'{request.node.name}_compile.pb'
                convert_to_perfetto(
                    {request.node.name: str(output_compile_profile)},
                    str(pb_output_path),
                    overview_map=overview_map
                )
                print(f"✓ Generated Perfetto trace: {pb_output_path}")
            except Exception as e:
                print(f"⚠ Warning: Could not generate Perfetto trace: {e}")
        else:
            print(f"⚠ Warning: Compiler profile CSV not found at {compiler_profile_csv}")


@versioned_unhashable_object_fixture
def torq_compiled_model(torq_compiled_model_dir):
    return torq_compiled_model_dir / 'model.vmfb'


@versioned_unhashable_object_fixture
def torq_compiled_hw_descriptors(torq_compiled_model_dir):
    return torq_compiled_model_dir / 'cfgdesc'


@versioned_unhashable_object_fixture
def torq_compiled_model_phases(torq_compiled_model_dir):
    return torq_compiled_model_dir / 'phases'


@versioned_hashable_object_fixture
def torq_runtime_options(request, case_config):
    cmds = case_config.get("torq_runtime_options", [])

    if request.config.getoption("--extra-torq-runtime-options"):
        cmds.extend(request.config.getoption("--extra-torq-runtime-options").split(" "))

    return cmds

@versioned_hashable_object_fixture
def enable_torq_buffer_tracing(request):
    return request.config.getoption("--trace-buffers")


@versioned_hashable_object_fixture
def enable_hw_test_vectors(request):
    return request.config.getoption("--generate-hw-test-vectors")


@versioned_hashable_object_fixture
def torq_runtime_timeout(request, case_config):
    return int(case_config.get("torq_runtime_timeout", request.config.getoption("--torq-runtime-timeout")))


@versioned_cached_data_fixture
def torq_mlir_func_name(request, mlir_model_file):
    with open(mlir_model_file, 'r') as mlir_file:
        mlir_content = mlir_file.read()

    all_lines = mlir_content.split('\n')
    func_name = "main"
    for line in all_lines:
        if re.match(r'^\s*(func.func).*', line):
            m = re.search(r'@(\w+)\s*\(', line)
            if m:
                func_name = m.group(1)
                break
            m = re.search(r'@"([^"]+)"\s*\(', line)
            if m:
                func_name = m.group(1)
                break
    #print(f"Detected MLIR function name: {func_name}")
    return func_name


@versioned_hashable_object_fixture
def enable_profiling(request):
    profiling_output_dir = request.config.getoption("--torq-runtime-profiling-output-dir")
    return profiling_output_dir is not None

@versioned_hashable_object_fixture
def skip_profile_annotation(request, case_config):
    return int(case_config.get("skip_profile_annotation", False))

@versioned_generated_directory_fixture
def torq_results_dir(versioned_dir, request, torq_compiled_model, iree_input_data_args, mlir_io_spec, 
                        torq_runtime, runtime_hw_type, torq_runtime_options, enable_torq_buffer_tracing, 
                        enable_hw_test_vectors, torq_runtime_timeout, chip_config, torq_mlir_func_name,
                        enable_profiling, skip_profile_annotation):

    output_args = create_output_args(versioned_dir, mlir_io_spec.outputs)

    cmds = [str(torq_runtime),
            '--device=torq',
            '--module=' + str(torq_compiled_model),
            '--function=' + torq_mlir_func_name,
            *output_args,
            '--torq_hw_type=' + runtime_hw_type,
            *torq_runtime_options,
            *iree_input_data_args]

    tv_dir = versioned_dir / 'tv'
    buffers_dir = versioned_dir / 'buffers'
    extra_runtime_opts = []

    if enable_hw_test_vectors:
        extra_runtime_opts.append('--torq_desc_data_dir=' + str(request.getfixturevalue("torq_compiled_hw_descriptors").data))
        extra_runtime_opts.append('--torq_dump_mem_data_dir=' + str(tv_dir))

    if enable_torq_buffer_tracing:
        extra_runtime_opts.append('--torq_dump_buffers_dir=' + str(buffers_dir))

    if enable_profiling:
        host_profile_path = versioned_dir / 'host_profile.csv'
        extra_runtime_opts.append(f'--torq_profile_host=' + str(host_profile_path))

    remote_addr = request.config.getoption("--torq-addr")
    if remote_addr:
        remote_port = request.config.getoption("--torq-port")
        all_runtime_opts = (
            list(torq_runtime_options)
            + list(extra_runtime_opts)
            + ['--device=torq', '--torq_hw_type='+runtime_hw_type]
        )
        print("Running for TORQ remotely with iree-run-module at " + remote_addr + ":" + str(remote_port))
        runner = RemoteTestRunner(
            torq_compiled_model,
            torq_mlir_func_name,
            iree_input_data_args,
            output_args,
            *all_runtime_opts,
            board_addr=remote_addr,
            port=remote_port,
            recompute_cache=request.config.getoption("--recompute-cache")
        )
        if runtime_hw_type == 'aws_fpga':
            port = request.config.getoption("--torq-port")
            with RemoteFpgaSession(chip_config['aws_fpga'], remote_addr, port) as fpga_session:
                with request.getfixturevalue("scenario_log").event("torq_run"):
                    runner.run(timeout=torq_runtime_timeout)
        else:
            with request.getfixturevalue("scenario_log").event("torq_run"):
                runner.run(timeout=torq_runtime_timeout)
    else:
        cmds += extra_runtime_opts
        print("Running for TORQ with: " + " ".join(cmds))
        if runtime_hw_type == 'aws_fpga':            
            with FpgaSession(chip_config['aws_fpga']) as fpga_session:
                with request.getfixturevalue("scenario_log").event("torq_run"):
                    subprocess.check_call(cmds, timeout=torq_runtime_timeout)
        else:
            with request.getfixturevalue("scenario_log").event("torq_run"):
                # FIXME: Depending on the platform and the model this will not be enough (tests with desc dumping are particularly slow).
                subprocess.check_call(cmds, timeout=torq_runtime_timeout)

    if enable_hw_test_vectors:
        print(f"Generated test vectors in {tv_dir}")

    if enable_torq_buffer_tracing:
        print("\nBuffer tracing enabled\n")
        print("Buffer trace will be available in: " + str(buffers_dir) + "\n")
        print("To view the buffer trace run:")

        ir_dir = request.getfixturevalue("torq_compiled_model_phases").data

        ir_path = ""

        if os.path.exists(ir_dir):
            for irs in os.listdir(ir_dir):
                if irs.endswith('9.executable-targets.mlir'):
                    ir_path = str(Path(ir_dir) / irs)
                    break


        print(f"cd {TOPDIR} && streamlit run webapps/buffer_viewer/buffer_viewer.py {buffers_dir} {ir_path}")
        print()
    
    # Check if profile annotation should be skipped (can be configured via case_config)
    if enable_profiling and not skip_profile_annotation:
        logger.debug("Starting profile annotation...")
        ir_path = ""
        ir_dir = request.getfixturevalue("torq_compiled_model_phases").data
        logger.debug(f"Got torq_compiled_model_phases: {ir_dir}")
        if os.path.exists(ir_dir):
            logger.debug("IR dir exists, scanning for files...")
            for irs in os.listdir(ir_dir):
                if irs.endswith('9.executable-targets.mlir'):
                    ir_path = str(Path(ir_dir) / irs)
                    logger.debug(f"Found IR file: {ir_path}")
                    
                    original_mlir_file = None
                    try:
                        logger.debug("Getting mlir_model_file fixture...")
                        # Attempt to get the original MLIR file path
                        mlir_model_file_obj = request.getfixturevalue("mlir_model_file")
                        # Handle VersionedFile or similar wrapper objects
                        if hasattr(mlir_model_file_obj, 'file_path'):
                            original_mlir_file = str(mlir_model_file_obj.file_path)
                        elif hasattr(mlir_model_file_obj, 'data'):
                            original_mlir_file = str(mlir_model_file_obj.data)
                        else:
                            original_mlir_file = str(mlir_model_file_obj)
                        logger.debug(f"Original MLIR file: {original_mlir_file}")
                    except Exception as e:
                        # This is optional, so we ignore errors if the fixture is not available
                        logger.debug(f"Could not get original MLIR file: {e}")
                        pass

                    logger.debug("Calling annotate_host_profile_from_files...")
                    annotate_host_profile_from_files(
                        ir_path,
                        str(versioned_dir / 'host_profile.csv'),
                        str(versioned_dir / 'annotated_profile.xlsx'),
                        original_mlir_file=original_mlir_file,
                        perfetto_file=str(versioned_dir / 'trace.pb')
                    )
                    logger.debug("Profile annotation completed")
        else:
            logger.debug(f"IR dir does not exist: {ir_dir}")

@versioned_unhashable_object_fixture
def torq_results(request, torq_results_dir, mlir_io_spec):

    profiling_output_dir = request.config.getoption("--torq-runtime-profiling-output-dir")
    
    if profiling_output_dir is not None:
        record_property = request.getfixturevalue("record_property")
        profiling_output_dir = Path(profiling_output_dir)
        profiling_output_dir.mkdir(parents=True, exist_ok=True)
        shutil.copy(torq_results_dir / 'host_profile.csv', profiling_output_dir / f'{request.node.name}.csv')
        record_property("host_profile_csv", str(profiling_output_dir / f'{request.node.name}.csv'))
        if (torq_results_dir / 'annotated_profile.xlsx').exists():
            shutil.copy(torq_results_dir / 'annotated_profile.xlsx', profiling_output_dir / f'{request.node.name}.xlsx')
        if (torq_results_dir / 'trace.pb').exists():
            pb_output_path = profiling_output_dir / f'{request.node.name}.pb'
            shutil.copy(torq_results_dir / 'trace.pb', pb_output_path)
            # Record the path to the copied .pb file for reporting
            record_property("profiling_output", str(pb_output_path))
        
        # Generate combined HTML report with all profiling artifacts
        pb_files = sorted(profiling_output_dir.glob('*.pb'))
        if pb_files:
            html_content = generate_html(pb_files)
            html_output_path = profiling_output_dir / 'perfetto_viewer.html'
            with open(html_output_path, 'w', encoding='utf-8') as f:
                f.write(html_content)
            print(f"✓ Generated profiling report: {html_output_path}")

    output_paths = create_output_paths(torq_results_dir, mlir_io_spec.outputs)
    return load_outputs(mlir_io_spec.outputs, output_paths)


@versioned_hashable_object_fixture
def llvmcpu_compiler_options(request, case_config):
    cmds = case_config.get("llvmcpu_compiler_options", [])

    if request.config.getoption("--llvmcpu-compiler-options"):
        cmds.extend(request.config.getoption("--llvmcpu-compiler-options").split(" "))

    return cmds

@versioned_hashable_object_fixture
def llvmcpu_runtime_options(request, case_config):
    cmds = case_config.get("llvmcpu_runtime_options", [])

    if request.config.getoption("--llvmcpu-runtime-options"):
        cmds.extend(request.config.getoption("--llvmcpu-runtime-options").split(" "))

    return cmds

@versioned_generated_file_fixture("vmfb")
def llvmcpu_compiled_model(versioned_file, llvmcpu_compiler, request, mlir_model_file, llvmcpu_compiler_options):

    cmd = [str(llvmcpu_compiler),
           '--iree-hal-target-backends=llvm-cpu',
           str(mlir_model_file),
           *llvmcpu_compiler_options,
           '-o', str(versioned_file)]

    print("Compiling for LLVMCPU with: " + " ".join(cmd))

    subprocess.check_call(cmd)


@versioned_generated_directory_fixture
def llvmcpu_reference_results_dir(versioned_dir, request,
    llvmcpu_runtime, llvmcpu_compiled_model, iree_input_data_args, mlir_io_spec,
    torq_mlir_func_name, llvmcpu_runtime_options):

    output_args = create_output_args(versioned_dir, mlir_io_spec.outputs)

    cmd = [str(llvmcpu_runtime),
           '--device=local-task',
           '--module=' + str(llvmcpu_compiled_model),
           '--function=' + torq_mlir_func_name,
           *llvmcpu_runtime_options,
           *output_args,
           *iree_input_data_args]

    print("Running for LLVMCPU with: " + " ".join(cmd))

    subprocess.check_call(cmd)
    

@versioned_unhashable_object_fixture
def llvmcpu_reference_results(llvmcpu_reference_results_dir, mlir_io_spec):
    output_paths = create_output_paths(llvmcpu_reference_results_dir, mlir_io_spec.outputs)
    return load_outputs(mlir_io_spec.outputs, output_paths)


@pytest.fixture
def input_data(request, case_config):
    return request.getfixturevalue(case_config['input_data'])


@versioned_cached_data_fixture
def random_uniform_input_data(request, mlir_io_spec):

    result = []

    rng = np.random.default_rng(1234)

    for inp_spec in mlir_io_spec.inputs:
        dtype = get_dtype(inp_spec.fmt)

        if not np.issubdtype(dtype, np.integer):
            raise ValueError("Requested random uniform integer data for float type")

        data = rng.integers(np.iinfo(dtype).min, np.iinfo(dtype).max, size=inp_spec.shape, dtype=dtype)

        result.append(data)

    return result


@versioned_hashable_object_fixture
def tweaked_random_input_data_ranges(mlir_io_spec, case_config):

    random_ranges = []
    for tensor_type in mlir_io_spec.data.inputs:

        dtype = get_dtype(tensor_type.fmt)

        if "tweaked_input_data_range" in case_config:
            random_range = case_config["tweaked_input_data_range"]
        else:
            # TODO: there are many issues when we enable the full range
            # for now we limit the range to avoid issues
            if dtype == np.uint8:
                random_range = (0, 80)
            else:
                random_range = (-40, 40)

        random_ranges.append(random_range)

    return random_ranges

@versioned_cached_data_fixture
def tweaked_random_input_data(request, mlir_io_spec, tweaked_random_input_data_ranges):
    rng = np.random.default_rng(1234)

    input_tensors = []

    for idx, tensor_type in enumerate(mlir_io_spec.inputs):

        random_range = tweaked_random_input_data_ranges[idx]
        dtype = get_dtype(tensor_type.fmt)
        if is_float_type(dtype):
            tensor = rng.uniform(random_range[0],
                                    random_range[1], tensor_type.shape).astype(dtype)
        elif np.issubdtype(dtype, np.integer):
            tensor = rng.integers(random_range[0], random_range[1],
                                    tensor_type.shape, dtype=dtype)
        elif dtype is bool:
            tensor = rng.integers(0, 2, tensor_type.shape, dtype=dtype)
        else:
            raise ValueError(f"Unsupported dtype {dtype}")

        input_tensors.append(tensor)

    return input_tensors


def _list_files(path_name: Path, suffix=None):
    test_files = []

    if not path_name.exists():
        return []

    for file in path_name.iterdir():
        if file.name.startswith('disable'):
            continue

        if suffix is None:
            test_files.append(path_name / file)
        else:
            if file.suffix == suffix:
                test_files.append(path_name / file)

    return test_files

def list_files(dir_name, suffix=None, extras=True):
    """
    Creates pytest parameters for all files in the specified testdata subdirectory
    """

    test_files = []

    testdata_dir = TOPDIR / 'tests' / 'testdata' / dir_name

    if not testdata_dir.exists():
        return []

    test_files = _list_files(testdata_dir, suffix)

    if extras:
        extra_dir = TOPDIR / 'extras/tests/testdata' / dir_name

        if extra_dir.exists():
            test_files.extend(_list_files(extra_dir, suffix))

    return sorted(test_files)


def list_mlir_files(dir_name):
    """
    Creates pytest parameters for all mlir files in the specified testdata subdirectory
    """
    return list_files(dir_name, ".mlir")


def list_mlir_file_group(group_name):

    root_dirs = [ TOPDIR / 'tests', TOPDIR / 'extras' / 'tests' ]

    files = []

    for root_dir in root_dirs:

        test_data_group = root_dir / 'testdata' / ( group_name + '.group')

        if not test_data_group.exists():
            continue

        with open(test_data_group, 'r') as f:
            groups = [ x.strip() for x in f.readlines()]

        for group in groups:
            
            dir_name = root_dir / 'testdata' / group

            if not dir_name.exists():
                continue

            files.extend(_list_files(dir_name, ".mlir"))

    return sorted(files)


@versioned_static_file_fixture
def static_mlir_model_file(request, case_config):
    return case_config["static_mlir_model_file"]    


@versioned_cached_data_fixture
def comparison_config_from_mlir(request, mlir_model_file):
    """
    Extract comparison configuration directives from MLIR file comments

    These values will update the default comparison configuration used in tests.
    """

    tols = {}

    for line in open(mlir_model_file).readlines():
        if "TORQ_" in line:
            _, directive, value = line.split()
            tols[directive[5:-1].lower()] = float(value)

    return tols
