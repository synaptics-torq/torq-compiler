description: Run Torq compiler tests

inputs:

  release_run_id:
    description: 'Run ID of the build to test against'
    default: ${{ github.run_id }}
    required: false

  hf_token:
    description: 'HuggingFace Token'
    required: true

  pytest_args:
    description: 'Arguments to pass to pytest'
    required: true

  app_id:
    description: 'GitHub App ID'
    required: false
  
  app_private_key:
    description: 'GitHub App Private Key'
    required: false

  extra_repo:
    description: 'Extras repository to checkout'
    required: false

  test_data_cache_artifact:
    description: 'Name of the test data cache artifact to generate'
    required: false

  precomputed_cache:
    description: 'S3 path to precomputed test data cache artifact to download'
    required: false

  s3_bucket:
    description: 'S3 bucket to upload the test cache artifact'
    required: false
    default: ''

  torq_perf_server:
    description: 'Torq Performance Server URL'
    required: false
    default: ''
    
  torq_perf_server_token:
    description: 'Torq Performance Server Token'
    required: false
    default: ''

  batch_name:
    description: 'Name of the test run batch for Torq reporting.'
    required: false
    default: 'default'

  torq_perf_space_url:
    description: 'Base URL of the Torq Performance Space'
    required: false
    default: ''

outputs:
  s3_cache_path:
    description: 'S3 path of the uploaded test data cache artifact'
    value: ${{ steps.upload_s3.outputs.s3_cache_path }}

runs:
  using: "composite"
  steps:

    - name: Generate GitHub token
      id: generate_token
      uses: actions/create-github-app-token@v1
      if: ${{ inputs.app_id != '' }}
      with:
        app-id: ${{ inputs.app_id }}
        private-key: ${{ inputs.app_private_key }}
        owner: ${{ github.repository_owner }}

    - name: Check if there is a branch for extras
      id: check_branch      
      if: ${{ inputs.extra_repo != '' }}
      shell: bash
      run: |
        token="${{ steps.generate_token.outputs.token }}"
        branch_name="${{ github.head_ref || github.ref_name }}"
        repo="${{ inputs.extra_repo }}"

        status=$(curl -s -o /dev/null -w "%{http_code}" \
          -H "Authorization: Bearer $token" \
          "https://api.github.com/repos/$repo/branches/$branch_name")

        if [ "$status" = "200" ]; then
          echo "branch=$branch_name" >> $GITHUB_OUTPUT
        else
          echo "branch=main" >> $GITHUB_OUTPUT
        fi

    - name: Checkout extras repository
      uses: actions/checkout@v4
      if: ${{ inputs.extra_repo != '' }}
      with:
        repository: ${{ inputs.extra_repo }}
        path: extras
        token: ${{ steps.generate_token.outputs.token }}
        ref: ${{ steps.check_branch.outputs.branch }}

    - name: Download the compiler and runtime
      uses: actions/download-artifact@v4
      with:
        name: release
        path: .
        run-id: ${{ inputs.release_run_id }}
        github-token: ${{ steps.generate_token.outputs.token }}

    - name: Extract the compiler and runtime
      shell: bash
      run: |
        tar -zxf release.tar.gz

    - name: Setup python virtualenv with on release files
      shell: bash
      run: |
        pip install -r ${{github.workspace}}/release/python/requirements.txt

        pip install ${{github.workspace}}/release/python/iree_tf
        pip install ${{github.workspace}}/release/python/iree_tflite

        cat > $(python -c "import site; print(site.getsitepackages()[0])")/iree.pth << EOF
        ${{github.workspace}}/release/python/compiler
        ${{github.workspace}}/release/python/runtime
        EOF

        # add development libraries which are not included in the release
        cat > $(python -c "import site; print(site.getsitepackages()[0])")/torq.pth << EOF
        ${{github.workspace}}/python
        EOF

    - name: Install boto3
      shell: bash
      run: |
        pip3 install boto3

    - name: Download precomputed test cache
      if: ${{ inputs.precomputed_cache != '' }}
      shell: bash
      env:
        PRECOMPUTED_CACHE: ${{ inputs.precomputed_cache }}
      run: |        
        set -x

        mkdir -p .pytest_cache/d/
        cd .pytest_cache/d/

        python3 - <<EOF
        import boto3        
        import os

        s3_path = os.environ['PRECOMPUTED_CACHE']
        bucket, key = s3_path.replace("s3://", "").split("/", 1)

        s3 = boto3.client("s3")

        print("Downloading precomputed cache from", s3_path)
        s3.download_file(bucket, key, "cache.tar.gz")
        EOF
        
        tar -zxf cache.tar.gz
        rm cache.tar.gz

    - name: Run pytest
      shell: bash
      env:
        LD_LIBRARY_PATH: ${{github.workspace}}/release/lib/
        SOC_TORQ_RUN_MODULE: ${{github.workspace}}/release/tools/armhf-torq-run-module
        TORQ_RUN_MODULE: ${{github.workspace}}/release/tools/torq-run-module
        TORQ_COMPILE: ${{github.workspace}}/release/tools/torq-compile
        IREE_RUN_MODULE: ${{github.workspace}}/release/tools/iree-run-module
        IREE_COMPILE: ${{github.workspace}}/release/tools/iree-compile
        IREE_OPT: ${{github.workspace}}/release/tools/iree-opt
        HF_TOKEN: ${{ inputs.hf_token }}
        TORQ_PERF_SERVER: ${{ inputs.torq_perf_server }}
        TORQ_PERF_SERVER_TOKEN: ${{ inputs.torq_perf_server_token }}
        TORQ_PERF_BATCH_NAME: ${{ inputs.batch_name }}
        TORQ_PERF_SPACE_URL: ${{ inputs.torq_perf_space_url }}
      run: |            
        # run pytest with ignoring binary mtime changes to generate a cache that can be used in other environments,
        # also disable phases dump to reduce size of the cache
        pytest --ignore-binary-mtime -v ${{ inputs.pytest_args }}

    - name: Create compressed test data cache artifact
      if: ${{ inputs.test_data_cache_artifact != '' || inputs.s3_bucket != '' }}
      shell: bash
      run: |
        tar -zcf cache.tar.gz -C .pytest_cache/d/ versioned_fixtures

    - name: Upload test data cache to GitHub
      if: ${{ inputs.test_data_cache_artifact != '' }}
      uses: actions/upload-artifact@v4
      with:
        name: ${{ inputs.test_data_cache_artifact }}
        path: cache.tar.gz
        retention-days: 7 # delete quickly because these are very large

    - name: Upload cache to S3
      if: ${{ inputs.s3_bucket != '' }}
      id: upload_s3
      shell: bash
      env:        
        S3_BUCKET: ${{ inputs.s3_bucket }}
        CACHE_FILE: 
      run: |

        set -x

        python3 - <<EOF
        import os
        import uuid
        import boto3

        artifact_name = f"artifact-{uuid.uuid4()}.tar.gz"

        s3_bucket = os.environ['S3_BUCKET']

        s3 = boto3.client("s3")

        # we need to monkey patch boto3 because the ifnonematch header is not yet supported
        # (see https://github.com/boto/boto3/issues/4366)
        import s3transfer
        boto3.s3.transfer.S3Transfer.ALLOWED_UPLOAD_ARGS.append("IfNoneMatch")
        s3transfer.upload.UploadSubmissionTask.CREATE_MULTIPART_BLOCKLIST.append("IfNoneMatch")
        s3transfer.upload.UploadSubmissionTask.PUT_OBJECT_BLOCKLIST.append("IfNoneMatch")
        s3transfer.upload.UploadSubmissionTask.COMPLETE_MULTIPART_ARGS.append("IfNoneMatch")
        
        print(f"Uploading cache to s3://{s3_bucket}/{artifact_name}")

        # force to use multipart to ensure the above monkey patch is used
        config = boto3.s3.transfer.TransferConfig(multipart_threshold=1)

        # Add If-None-Match header to avoid overwriting if the object exists (required by policy)
        s3.upload_file("cache.tar.gz", s3_bucket, artifact_name, ExtraArgs={"IfNoneMatch": "*"}, Config=config)

        # Output the S3 path for GitHub Actions        
        with open(os.environ["GITHUB_OUTPUT"], "a") as out:
          out.write(f"s3_cache_path=s3://{s3_bucket}/{artifact_name}\n")
        EOF
